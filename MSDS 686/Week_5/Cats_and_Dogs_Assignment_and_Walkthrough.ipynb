{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cats and Dogs Assignment and Walkthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gml_xoheS5MF"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xxBqGLGQ_kDh"
      },
      "source": [
        "## This tutorial was adapted from Cholett (2021)\n",
        "## You will build a CNN using transfer learning and data augmentation. The data images have already been split into training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8nJxNX0S5MX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, shutil # Library for navigating files\n",
        "from keras import backend as K\n",
        "from keras import backend, models, layers, optimizers, regularizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import display # Library to help view images\n",
        "from PIL import Image # Library to help view images\n",
        "from keras.preprocessing.image import ImageDataGenerator # Library for data augmentation\n",
        "from keras.preprocessing import image\n",
        "\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR6c1cpY09x2"
      },
      "source": [
        "### We need to mount the google drive to access the images. Paste the authorization code into your browser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMNjfHNhixaa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive  # Library to mount google drives\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmVmwSt1S5Mx"
      },
      "outputs": [],
      "source": [
        "# Specify the base directory where images are located.  You need to access your data here.\n",
        "base_dir = '/content/gdrive/My Drive/Cats_and_Dogs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHMgzJfvS5M8"
      },
      "outputs": [],
      "source": [
        "# Specify the training, validation, and test directories.  \n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YChCnqH7S5NB"
      },
      "outputs": [],
      "source": [
        "# Specify the classess in the training, validataion, and test directories\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9TefFy2S5Nk"
      },
      "outputs": [],
      "source": [
        "# Check the number of files in each class dirrectory\n",
        "print(len(os.listdir(train_cats_dir)))\n",
        "print(len(os.listdir(train_dogs_dir)))\n",
        "print(len(os.listdir(validation_cats_dir)))\n",
        "print(len(os.listdir(validation_dogs_dir)))\n",
        "print(len(os.listdir(test_cats_dir)))\n",
        "print(len(os.listdir(test_dogs_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD39J_LxS5OL"
      },
      "outputs": [],
      "source": [
        "# We need to normalize the pixels in the images.  The data will 'flow' through this generator.\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQd1QktFS5OP"
      },
      "outputs": [],
      "source": [
        "# Since the file images are in a directory we need to move them from the directory into the model.  \n",
        "# Keras as a function that makes this easy. Documentaion is here: https://keras.io/preprocessing/image/\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # The directory where the train data is located\n",
        "    target_size=(150, 150), # Reshape the image to 150 by 150 pixels. This is important because it makes sure all images are the same size.\n",
        "    batch_size=20, # We will take images in batches of 20.\n",
        "    class_mode='binary') # The classification is binary.\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqNR8TyYLaeA"
      },
      "outputs": [],
      "source": [
        "# Build a plotting function\n",
        "def plot_history(history):\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict['loss']\n",
        "  val_loss_values = history_dict['val_loss']\n",
        "  acc_values = history_dict['accuracy']\n",
        "  val_acc_values = history_dict['val_accuracy']\n",
        "  epochs = range(1, len(history_dict['accuracy']) + 1)\n",
        "\n",
        "  plt.plot(epochs, loss_values, 'bo', label = 'Training loss')\n",
        "  plt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\n",
        "  plt.plot(epochs, val_acc_values, 'b', label = 'Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  return plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLdrG2n1L2oa"
      },
      "outputs": [],
      "source": [
        "# Build a model\n",
        "def Base_CNN():\n",
        "  backend.clear_session()\n",
        "  model = models.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (150, 150, 3)))\n",
        "  model.add(layers.MaxPool2D((2,2)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Conv2D(32, (3,3), activation = 'relu'))\n",
        "  model.add(layers.MaxPool2D((2,2)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Conv2D(32, (3,3), activation = 'relu'))\n",
        "  model.add(layers.MaxPool2D((2,2)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer = 'rmsprop',\n",
        "                loss = 'binary_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdBnSmU1HoPQ"
      },
      "outputs": [],
      "source": [
        "model = Base_CNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1oqUEMpvT2H"
      },
      "outputs": [],
      "source": [
        "history = model.fit( # The image data must come from the image generator that takes the images from the correct dirrectory. https://keras.io/models/sequential/\n",
        "    train_generator, # Images are taken from the train_generator\n",
        "    steps_per_epoch=100, # The number of steps from the train_generator before one epoch if finished.  \n",
        "                         # 100 steps * 20 batch size in train generator = 2000 training images per epoch. This way each traning image will be sampled once per epoch.\n",
        "    epochs=50, # Train data for 50 epochs\n",
        "    validation_data=validation_generator, # Take data from the validataion generator\n",
        "    validation_steps=50, # 50 steps * 20 batch size in validation generator = 1000 validation images per epoch\n",
        "    verbose = 1,\n",
        "    callbacks=[EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights = True)]) # We will not use call backs to stop early.\n",
        "\n",
        "plot_history(history) # Use our plot function to plot the loss and accuracy.\n",
        "\n",
        "test_loss, test_acc =model.evaluate(test_generator, steps = 50) # Test images are in a dirrectory so they must flow from dirrectory. \n",
        "                                                                           # 50 steps * 20 batch size in test generator = 1000 test images per epoch\n",
        "print('test_acc:', test_acc)\n",
        "\n",
        "model.save('cats_and_dogs_base.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7vRcaO1dKItm"
      },
      "source": [
        "### The above model came out with about 70% accuracy with severe overfitting, which is pretty good considering we only used 2000 training images!  Now let's improve using data augmentation.\n",
        "\n",
        "#### Data augmentation allows us to randomly transform images before sending them to the model for training.  The random transformation changes the images into 'new' images and allows for an increase in traning data without have additional images. https://keras.io/preprocessing/image/ \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lE-v1s-S5Og"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator( # The image augmentation function in Keras\n",
        "    rotation_range=40, # Rotate the images randomly by up to 40 degrees\n",
        "    width_shift_range=0.2, # Shift the image horizontally by up to 20%\n",
        "    height_shift_range=0.2, # Shift the image vertically by up to 20%\n",
        "    shear_range=0.2, # Shear image by up to 20%\n",
        "    zoom_range=0.2, # Zoom in on image by up to 20%\n",
        "    horizontal_flip=True, # Flip image horizontally \n",
        "    fill_mode='nearest'\n",
        "    ) # How to fill missing pixels after a augmentaion opperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6n24_ZUS5Oi"
      },
      "outputs": [],
      "source": [
        "# Let's see the image augmentaion\n",
        "image_batch, label_batch = next(iter(datagen.flow_from_directory(\n",
        "  train_dir, target_size=(150, 150), batch_size=32, class_mode='binary')))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "  label = ['Cat', 'Dog'][int(label_batch[i])]\n",
        "  plt.title(label)\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXgxrxmjS5Os"
      },
      "outputs": [],
      "source": [
        "# Apply the data augmentation to our data.\n",
        "train_datagen2 = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen2 = ImageDataGenerator(rescale=1./255) #Never apply data augmentation to test data.  You only want to normalize and resize test data. \n",
        "\n",
        "train_generator2 = train_datagen2.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator2 = train_datagen2.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator2 = test_datagen2.flow_from_directory( # Resize test data\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJFvmfqmS5On"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator2,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator2,\n",
        "    validation_steps=50,\n",
        "    verbose = 1,\n",
        "    callbacks=[EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights = True)])\n",
        "\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator2, steps = 50)\n",
        "print('test_acc:', test_acc)\n",
        "\n",
        "model.save('cats_and_dogs_base_augment.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q1jeroqqObPW"
      },
      "source": [
        "## An inprovement, but not a surprise. Having more data helps our accuracy. \n",
        "### But why go through the hassle of building our own CNN when there are many networks that have used powerful GPUs to classify images? We can use the weights of their models and apply them to something as simple as classiying a dog and cat.  We will use weights of the VGG16 CNN that was trained using ImageNet data.  https://keras.io/applications/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xidIScoOS5O0"
      },
      "outputs": [],
      "source": [
        "from keras.applications import VGG16 # Import the VGG16 library. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nbeVW1NS5O1"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "conv_base = VGG16 (weights = 'imagenet', #Using the VGG66 CNN that was trained on ImageNet data.  \n",
        "                  include_top = False, # We are using our own classification (dog or cat) and not the ImageNet multiclassification. So include top = false.\n",
        "                  input_shape = (150, 150, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e746eXq5S5O4"
      },
      "outputs": [],
      "source": [
        "conv_base.summary() # View the VGG16 model architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm1-txlUQmJ_"
      },
      "source": [
        "### The output shape of the data after the VGG16 weights are applied is (4, 4, 512).  Remember it started as (150, 150, 3).  This is from the 2D convolutions and maxpooling steps.  There are also over 14 million parameters to train.  This is way too many for the Google GPU. And we do not want to retrain the weights of the VGG16, that defeats the whole purpose of transfer learning.  Instead we will freeze the VGG16 weights and add a dense layer at the end.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqLz1oGSWckI"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = False # Freeze the VGG16 weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8LcggkAsp2C"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(conv_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KBREKXYWlk2"
      },
      "outputs": [],
      "source": [
        "conv_base.summary()# Lets look at the parameters now."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x3O0iAXbWs3p"
      },
      "source": [
        "### Now the trainable parameters are 0.  We will only use the pretrained VGG16 weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdXiFRx6S5Pa"
      },
      "outputs": [],
      "source": [
        "def modelvgg():\n",
        "  backend.clear_session()\n",
        "  modelvgg16 = models.Sequential()\n",
        "  modelvgg16.add(conv_base) # Add the VG166 weights\n",
        "  modelvgg16.add(layers.Flatten())\n",
        "  modelvgg16.add(layers.Dense(512, activation = 'relu'))\n",
        "  modelvgg16.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "  modelvgg16.compile(optimizer = 'rmsprop',\n",
        "                      loss = 'binary_crossentropy',\n",
        "                      metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "  return modelvgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwETvQtqH2le"
      },
      "outputs": [],
      "source": [
        "model = modelvgg()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI9hHNSZlk6b"
      },
      "outputs": [],
      "source": [
        "plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijIeC7J1S5Pn"
      },
      "outputs": [],
      "source": [
        "# We will still use data augmentation\n",
        "history = model.fit(\n",
        "    train_generator2,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator2,\n",
        "    validation_steps=50,\n",
        "    verbose = 1,\n",
        "    callbacks=[EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights = True)])\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator2, steps = 50)\n",
        "print('test_acc:', test_acc)\n",
        "\n",
        "model.save('cats_and_dogs_vgg.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EccdeBlhXq_K"
      },
      "source": [
        "### Our model keeps getting better. We might want to add a few 2D convolutions and max pooling layers before the dense layer, or we can train the last three 2D convolution layers and MaxPooling layer of the VGG16 model. We must be strategic when choosing which layers to train in the transfer model.  We want to train convolution, max pooling, batch normalization, etc., layers that are part of block.  It would not make sense to only train max pooling or batch normalization layers without also training the convolution layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGXPJvzoS5Pq"
      },
      "outputs": [],
      "source": [
        "# Now we can freeze all the VGG weights except the last few, and train those before adding it to our dense layer.\n",
        "backend.clear_session()\n",
        "vgg16_base_2 = VGG16(weights = 'imagenet', include_top = False, input_shape = (150, 150, 3))\n",
        "\n",
        "# Here we freeze all the layers except the last 2.\n",
        "for layer in vgg16_base_2.layers[:-2]:\n",
        "  layer.trainable = False\n",
        "for layer in vgg16_base_2.layers:\n",
        "  print(layer, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHl7lEDFC4Yu"
      },
      "outputs": [],
      "source": [
        "vgg16_base_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90mnL5tks0Lh"
      },
      "outputs": [],
      "source": [
        "plot_model(vgg16_base_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqh1znPCpea4"
      },
      "outputs": [],
      "source": [
        "def model_vgg_train():\n",
        "  backend.clear_session()\n",
        "  modelvgg16_train = models.Sequential()\n",
        "  modelvgg16_train.add(vgg16_base_2)\n",
        "  modelvgg16_train.add(layers.Flatten())\n",
        "  modelvgg16_train.add(layers.Dense(512, activation = 'relu'))\n",
        "  modelvgg16_train.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "  modelvgg16_train.compile('rmsprop',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy'])\n",
        "\n",
        "  return modelvgg16_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYuZcPb6IA-V"
      },
      "outputs": [],
      "source": [
        "model = model_vgg_train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOQLiSzZCWHY"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator2,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator2,\n",
        "    validation_steps=50,\n",
        "    verbose = 1,\n",
        "    callbacks=[EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights = True)])\n",
        "\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator2, steps = 50)\n",
        "print('test_acc:', test_acc)\n",
        "\n",
        "model.save('cats_and_dogs_small_vgg_train.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7uaQvzIw7_d"
      },
      "source": [
        "### The best model yet!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GsuF9mMLpDyY"
      },
      "source": [
        "# Your Turn\n",
        "### Build and optimize another model. Use weights from a different pretrained network (e.g., ResNet, Inception, etc. -- not VGG) from the [Keras library](https://keras.io/applications/). Optimize the model by adding additional layers, regularization, change activation, adjust data augmentation, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sri5vWATxg5G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cats_and_Dogs_Assignment_and_Walkthrough.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
