{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Deep_Learning_'Hello_MNIST'.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2-fHqdpQ4-hm"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1BMmhrW4-VF"
      },
      "source": [
        "# A tutorial introduction into deep learning with Keras and Tensorflow.  We will use the MNIST dataset which is the 'Hello world' problem of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfjjxqk-4-VY"
      },
      "source": [
        "I always like to start my jupternotebooks with this code because it fits the display window to my screen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq3zQaj94-Vf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ed6e5185-d158-45f9-95aa-8b4043fa3ea8"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:95% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTIiJaMH4-We"
      },
      "source": [
        "### This tutrial was adapted from Deep Learning with Python Chollet, F. (2021). Deep Learning with Python (2nd ed.). Greenwich, CT, USA: Manning Publications Co."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7J8caRE4-Wv"
      },
      "source": [
        "Start with some definitions.\n",
        "Numerical data in an array are called tensors.  https://en.wikipedia.org/wiki/Tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYhqLSfB4-W5"
      },
      "source": [
        "Scalars are 0 dimensional tensors (a single digit). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq1dfmTjXx1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0218956b-4eac-4aff-80f8-dedbb81f51e2"
      },
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 0 dimensions"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x is 12\n",
            "The dimension of this tensor is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd6j127g4-Xg"
      },
      "source": [
        "A 1 dimensional tensor is also called a vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iWxjAcgYF2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817533ae-fcf9-4d70-f35e-ca84d5cc8a05"
      },
      "source": [
        "x = np.array([12, 1, 2, 3]) #create a vector\n",
        "print('The value of x is', x)\n",
        "print('The dimention of this tensor is', x.ndim) # 1 dimensions"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x is [12  1  2  3]\n",
            "The dimention of this tensor is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZnkKqX74-YS"
      },
      "source": [
        "A 2 dimensional tensor is also called a matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw6vcniRYMga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b41adbb3-438c-4c71-83de-e2df4a64f157"
      },
      "source": [
        "x = np.array([[12, 1, 2, 3],\n",
        "              [5, 6, 7, 8,],\n",
        "              [10, 11, 12, 12]])\n",
        "print('The value of x is', x) # Print the 3 x 4 matrix\n",
        "print('The dimension of this tensor is', x.ndim) # 2 dimensions"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x is [[12  1  2  3]\n",
            " [ 5  6  7  8]\n",
            " [10 11 12 12]]\n",
            "The dimension of this tensor is 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDXBkNgF4-ZH"
      },
      "source": [
        "We can create n dimensional tensors easily, although they become difficult to visualize.\n",
        "This 3D tensor is like a cube of data.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unoEvdhYbYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecef453b-4c9b-420b-de09-deb80968aaaf"
      },
      "source": [
        "x = np.array([[[12, 1, 2, 3],\n",
        "               [5, 6, 7, 8,],\n",
        "               [10, 11, 12, 12]],\n",
        "              [[2, 2, 2, 2,],\n",
        "               [3,3,3,3],\n",
        "               [4,4,4,4]],\n",
        "              [[5,5,5,5],\n",
        "               [6,6,6,6],\n",
        "               [7,7,7,7]]])\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 3 dimensional array"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x is [[[12  1  2  3]\n",
            "  [ 5  6  7  8]\n",
            "  [10 11 12 12]]\n",
            "\n",
            " [[ 2  2  2  2]\n",
            "  [ 3  3  3  3]\n",
            "  [ 4  4  4  4]]\n",
            "\n",
            " [[ 5  5  5  5]\n",
            "  [ 6  6  6  6]\n",
            "  [ 7  7  7  7]]]\n",
            "The dimension of this tensor is 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QrNkyOM4-Z0"
      },
      "source": [
        "#### Reshaping tensors is important concept to understand.  We can reshape a tensor as long as it has the same number of coefficients as the initial tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5jul5ly4-Z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d87dab5-7730-46c5-9a99-9f9b72d85761"
      },
      "source": [
        "x = x.reshape(3*3*4,1)\n",
        "print(x)\n",
        "x = x.reshape(4, 3*3)\n",
        "print(x)\n",
        "x = x.reshape(2, 18)\n",
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12]\n",
            " [ 1]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [ 5]\n",
            " [ 6]\n",
            " [ 7]\n",
            " [ 8]\n",
            " [10]\n",
            " [11]\n",
            " [12]\n",
            " [12]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]]\n",
            "[[12  1  2  3  5  6  7  8 10]\n",
            " [11 12 12  2  2  2  2  3  3]\n",
            " [ 3  3  4  4  4  4  5  5  5]\n",
            " [ 5  6  6  6  6  7  7  7  7]]\n",
            "[[12  1  2  3  5  6  7  8 10 11 12 12  2  2  2  2  3  3]\n",
            " [ 3  3  4  4  4  4  5  5  5  5  6  6  6  6  7  7  7  7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihVQabEo4-aS"
      },
      "source": [
        "##### Tensors have three atributes: number of axis (dimensions), shape (length of each axis), and data type (typically we will use float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also manipulate tensors with TensorFlow"
      ],
      "metadata": {
        "id": "s2vP9ckYvLuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Tensorflow as tf\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "0XE9M6y1vULu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.ones(shape=(2,1))\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diW1WriOvbms",
        "outputId": "51eee45f-8ddc-4005-933a-d2aed4ff7af4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1.]\n",
            " [1.]], shape=(2, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tensorflow variable\n",
        "v = tf.Variable(initial_value=tf.random.normal(shape=(3,1)))\n",
        "print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMv_KG8pv6iq",
        "outputId": "e46ff584-d21b-4000-a949-74a69dfb3fc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[-1.1421368],\n",
            "       [ 0.5128755],\n",
            "       [ 2.0553992]], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Once the variable is createed it can be modified using assign\n",
        "v2 = v.assign(tf.random.normal(shape=(3,1)))\n",
        "print(v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iljsFGcewSIE",
        "outputId": "eeb6215a-b095-4c3b-ef11-e0d622420e73"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'UnreadVariable' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[-1.4786801],\n",
            "       [-1.521925 ],\n",
            "       [-0.9422084]], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can perform some math operations on the tensors\n",
        "np.dot(v, v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "FGkCIydvw2Ks",
        "outputId": "d9f23e59-d032-4901-9635-a5cb292fef31"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7f70adf26429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now we can perform some math operations on the tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (3,1) and (3,1) not aligned: 1 (dim 1) != 3 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We get the above error because the shapes of v and v2 do not align properly for a dot product.\n",
        "print(v.shape)\n",
        "print(v2.shape)\n",
        "\n",
        "# For a dot product to alight the column rows of X must match the rows of Y. (See Figure 2.5 in book)\n",
        "# Therefore, we must transpost v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdzH71UFxQ2Q",
        "outputId": "2bd085c3-b19e-45a0-80c4-255ae9e688d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "(3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v3 = np.transpose(v2)\n",
        "print(v.shape)\n",
        "print(v3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSctb3a0x8l-",
        "outputId": "5e252812-c06f-41f7-fc72-e2abb56e475c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "(1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the rows of v match the columns of v3 we can take the dot product\n",
        "np.dot(v, v3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l560ng4tyOdG",
        "outputId": "1401c1e5-b68e-4878-bb63-a7788a05cbc8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.1864948, 2.2504401, 1.3932248],\n",
              "       [2.2504401, 2.3162556, 1.4339705],\n",
              "       [1.3932248, 1.4339705, 0.8877567]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUA1N4pS4-aY"
      },
      "source": [
        "# Let's build our first neural net\n",
        "\n",
        "Load the MNIST library which is part of Keras.  MNIST stands for Modified National Institute of Technology. https://en.wikipedia.org/wiki/MNIST_database. It is a collection of 60,000 training and 10,000 test images of the digits 0-9. https://keras.io/datasets/. We will build a deep learning nerual net model to classify the 10 digits. This is the 'Hello World' problem of deep learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AG-iMB8P3DZ"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Efu6_zaQKtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0201a521-40c2-4a79-df52-58bd36ab51b8"
      },
      "source": [
        "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYu3aOo4Qn9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11588739-9869-4887-c4b2-e6b38fcd5398"
      },
      "source": [
        "train_images.shape #60,000 images that are 28 pixles by 28 pixles."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73Jt87YRZBXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb7494e-3688-42ac-bbdf-7dbc42da474a"
      },
      "source": [
        "train_images.ndim #3D tensor"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_fgMe2h4-bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb04c5da-70d0-4f60-8215-c16f51660a63"
      },
      "source": [
        "print('The maximum value in the array is', train_images.max()) # The maximum value in the array is 255\n",
        "print('he minimum value in the array is', train_images.min()) # The minimum value in the array is 0"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum value in the array is 255\n",
            "he minimum value in the array is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACNHKDMhZMtH"
      },
      "source": [
        "# Get the shape, dimensions, max and min value of the test images"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvcS2anBQ8cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af9eb13-4f9b-4ac2-f223-a7012a743d68"
      },
      "source": [
        "print('test image shape:', test_images.shape)\n",
        "print('number of dimensions:', test_images.ndim)\n",
        "print('maximum value', test_images.max())\n",
        "print('minimum value:', test_images.min())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test image shape: (10000, 28, 28)\n",
            "number of dimensions: 3\n",
            "maximum value 255\n",
            "minimum value: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAWThxtY4-co"
      },
      "source": [
        "In general the first axis in a tensor is the samples, the second axis is height, the third axis is the width, and the fourth is color channels (RGB = 3 & BW = 1)\n",
        "So image data will be a 4D tensor [samples, height, width, channels] the MNIST data is 3D bacause the color channel is black and white and thus = 1\n",
        "Video data will be a 5D tensor [samples, frames, height, width, channels]. By convention, time series data will be placed on the secod axis when present"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kavsqyWG4-cZ"
      },
      "source": [
        "Let's view one of the images.  We need to import matplotlib to view the digits "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwEiakpiZXnf"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvYknn0hZf51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a6e694f1-daf4-4f23-f256-789f18c69cb2"
      },
      "source": [
        "digit = train_images[4] # Select the fouth sample.\n",
        "plt.imshow(digit, cmap=plt.cm.binary) # Show the sample.  cmap is the color map.  We will keep it black and white (binary)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 4th train image looks like the number 9.  Lets make sure the label matches."
      ],
      "metadata": {
        "id": "8_eEPRIC9bb1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srjlYOAavZUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e19ecc-281a-49a1-a276-c7af5fb91e5a"
      },
      "source": [
        "train_labels[4]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBcnrgsRPJ3"
      },
      "source": [
        "# Import models and layers from the tenforflow and keras libraries\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be working with sequential models and dense layers. More on what those mean later.  Another name for a dense layer is a fully connected layer.  The dense layer must be one dimentional. Therefore, the input shape must be reshaped into a vector. There are 60,000 test images with a shape of 28 x 28. We will reshape the matrix into a vector that is 28 * 28 == 784.\n",
        "\n",
        "We pick the 'relu' activation function for our first layer and our output layer activation function is 'softmax' because we have a multi-classification problem."
      ],
      "metadata": {
        "id": "CWKxgF2L9_xG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8lxhcrHRV0x"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we complie the model.  We use the 'adam' optimizer and choose 'catergorical crossentropy' for the loss function because it is a multi-classification problem. We will evaluate our model accuracy."
      ],
      "metadata": {
        "id": "JkdeEsM8FztX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcixP8_xR5j7"
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the model is built and compiled we need to process the images for the model.  The images need to be reshaped into a vector of the same dimentions as the input shape above.  We also normalize the values of the images to be between 0 and 1."
      ],
      "metadata": {
        "id": "ERD4fJuF_n2l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEeckA5ESIMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7ac0ee-8f1d-4fc7-bff8-e278998bf644"
      },
      "source": [
        "train_images =  train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32')/train_images.max()\n",
        "\n",
        "test_images =  test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32')/test_images.max()\n",
        "\n",
        "print(train_images.ndim)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw_1wSzI4-ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ccfb6ff-1115-4519-c463-36d790015352"
      },
      "source": [
        "print('train image shape:', train_images.shape)\n",
        "print('number of dimensions:', train_images.ndim)\n",
        "print('maximum value', train_images.max())\n",
        "print('minimum value:', train_images.min())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train image shape: (60000, 784)\n",
            "number of dimensions: 2\n",
            "maximum value 1.0\n",
            "minimum value: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can always get our images back by reshaping to a matrix.\n",
        "plt.imshow(train_images.reshape((60000,28,28))[4], cmap=plt.cm.binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "q8QVj91nADix",
        "outputId": "e9a14f48-9a93-438b-b843-0708a73dbd8b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f993c075c90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeczsZHUVDQx"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to convert the labels into catergorical values.\n",
        "# We can check the train lables for the 4th value to ensure\n",
        "# it is labeled as 9\n",
        "print(train_labels[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9u7dxrQGsi8",
        "outputId": "9599b16d-28c9-4589-c290-c828205bb57b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w90ZrgWhVPC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e201173-603f-4152-c0ce-ad32f6a9e3ff"
      },
      "source": [
        "# Batch size is how many images to process at once. \n",
        "# Epoch is how many times to repeat the analysis.  \n",
        "# Each epoch performs 500 gradient updates (60,000/120 = 500)\n",
        "model.fit(train_images, train_labels, epochs = 5, batch_size = 120) "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "500/500 [==============================] - 4s 3ms/step - loss: 0.2637 - accuracy: 0.9243\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1085 - accuracy: 0.9675\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0704 - accuracy: 0.9796\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9848\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f993c02b690>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHqqd_YYVdz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d8c888-b886-482f-fbf3-6d8b43680b91"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.9777\n",
            "test_acc: 0.9776999950408936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIRCQyZ2F24o"
      },
      "source": [
        "# Your Turn.\n",
        "# Below is your assignmnet\n",
        "####  Build 3 different models with activations 'relu'.  The last activation must be 'softmax' since we have a multiclass problem.  You will comple the three different models with different optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgHnMI6T4-f6"
      },
      "source": [
        "model1 = models.Sequential()\n",
        "model1.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "model1.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model2 = models.Sequential()\n",
        "model2.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "model2.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model3 = models.Sequential()\n",
        "model3.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "model3.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnUDSgXk4-gE"
      },
      "source": [
        "#### Compile your three models with three different optimizers. Page 89 - 90 of the tetbook list some different optimizers.  You can also find more optimizers and documentation here: https://keras.io/api/optimizers/\n",
        "#### Use categorical_crossentropy since this problem is a multiclassification problem. Metrics will be 'accuracy'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhHGydeC4-gH"
      },
      "source": [
        "model1.compile(optimizer = 'adam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])\n",
        "\n",
        "model2.compile(optimizer = 'rmsprop',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])\n",
        "\n",
        "model3.compile(optimizer = 'nadam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7uSP2vm4-gR"
      },
      "source": [
        "#### Fit the models with epochs = 5 and  batch_size = 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9qFLRMA4-gT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e60f3d8c-496a-42ac-f954-63a147620938"
      },
      "source": [
        "model1.fit(train_images, train_labels, epochs = 5, batch_size = 120)\n",
        "model2.fit(train_images, train_labels, epochs = 5, batch_size = 120)\n",
        "model3.fit(train_images, train_labels, epochs = 5, batch_size = 120)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2636 - accuracy: 0.9237\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1067 - accuracy: 0.9683\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0688 - accuracy: 0.9796\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0485 - accuracy: 0.9855\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.9897\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2551 - accuracy: 0.9260\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1021 - accuracy: 0.9695\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0685 - accuracy: 0.9796\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.9890\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2685 - accuracy: 0.9255\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1051 - accuracy: 0.9700\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0681 - accuracy: 0.9805\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0474 - accuracy: 0.9862\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0346 - accuracy: 0.9900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f992584d350>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB4RPCz54-gb"
      },
      "source": [
        "#### Test the accuracy of the model on the test images and test labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7V6DjwV4-gc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d2e3bf-f152-40d8-c404-537050c8407d"
      },
      "source": [
        "test_loss, test_acc = model1.evaluate(test_images, test_labels)\n",
        "print('model1_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = model2.evaluate(test_images, test_labels)\n",
        "print('model2_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = model3.evaluate(test_images, test_labels)\n",
        "print('model3_test_acc:', test_acc)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0670 - accuracy: 0.9795\n",
            "model1_test_acc: 0.9794999957084656\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.9799\n",
            "model2_test_acc: 0.9799000024795532\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0704 - accuracy: 0.9783\n",
            "model3_test_acc: 0.9782999753952026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbR0ds5G4-gm"
      },
      "source": [
        "# Which optimizer gave the highest accuracy?\n",
        "### Using the opiomizer that gave the highest accuracy compile 3 different models with 3 hidden layers and varying units in each hidden layer.  The first and output layers are given to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTh369rD4-gr"
      },
      "source": [
        "h1_model = models.Sequential()\n",
        "h1_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "h1_model.add(layers.Dense(1028, activation='relu'))\n",
        "h1_model.add(layers.Dense(1028, activation='relu'))\n",
        "h1_model.add(layers.Dense(512, activation='relu'))\n",
        "h1_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "h2_model = models.Sequential()\n",
        "h2_model.add(layers.Dense(10, activation='relu',input_shape=(28 * 28,)))\n",
        "h2_model.add(layers.Dense(20, activation='relu'))\n",
        "h2_model.add(layers.Dense(40, activation='relu'))\n",
        "h2_model.add(layers.Dense(60, activation='relu'))\n",
        "h2_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "h3_model = models.Sequential()\n",
        "h3_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "h3_model.add(layers.Dense(512, activation='relu'))\n",
        "h3_model.add(layers.Dense(512, activation='relu'))\n",
        "h3_model.add(layers.Dense(512, activation='relu'))\n",
        "h3_model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY-vLrzS4-g1"
      },
      "source": [
        "#### Complie the three models with the best optimizer from above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvYLN-Ld4-g3"
      },
      "source": [
        "h1_model.compile(optimizer = 'nadam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])\n",
        "\n",
        "h2_model.compile(optimizer = 'nadam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])\n",
        "\n",
        "h3_model.compile(optimizer = 'nadam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRMZ56yI4-hF"
      },
      "source": [
        "\\#### Fit the models with epochs = 5 and  batch_size = 120"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO_mcJ9x4-hI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1566028-8370-4873-eb36-9c7e4415ab75"
      },
      "source": [
        "h1_model.fit(train_images, train_labels, epochs = 5, batch_size = 120)\n",
        "h2_model.fit(train_images, train_labels, epochs = 5, batch_size = 120)\n",
        "h3_model.fit(train_images, train_labels, epochs = 5, batch_size = 120)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "500/500 [==============================] - 4s 5ms/step - loss: 0.2234 - accuracy: 0.9322\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0838 - accuracy: 0.9739\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0561 - accuracy: 0.9832\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0466 - accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0374 - accuracy: 0.9890\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 3s 4ms/step - loss: 0.6045 - accuracy: 0.8068\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2755 - accuracy: 0.9183\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2320 - accuracy: 0.9297\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2085 - accuracy: 0.9378\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1921 - accuracy: 0.9420\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.2194 - accuracy: 0.9332\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0826 - accuracy: 0.9745\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0577 - accuracy: 0.9826\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0422 - accuracy: 0.9868\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0362 - accuracy: 0.9883\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9900771910>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Kcmj6x4-hU"
      },
      "source": [
        "#### Test the accuracy of the 3 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRUw9R5F4-ha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce02d8f8-ebb8-4334-b8ad-99e5c509df34"
      },
      "source": [
        "test_loss, test_acc = h1_model.evaluate(test_images, test_labels)\n",
        "print('h1_model_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = h2_model.evaluate(test_images, test_labels)\n",
        "print('h2_model_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = h3_model.evaluate(test_images, test_labels)\n",
        "print('h3_model_model_model_test_acc:', test_acc)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9773\n",
            "h1_model_test_acc: 0.9772999882698059\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2044 - accuracy: 0.9398\n",
            "h2_model_test_acc: 0.9398000240325928\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9779\n",
            "h3_model_model_model_test_acc: 0.9779000282287598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-fHqdpQ4-hm"
      },
      "source": [
        "#### Which model gave the highest accuracy?"
      ]
    }
  ]
}