{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1BMmhrW4-VF"
      },
      "source": [
        "# A tutorial introduction into deep learning with Keras and Tensorflow.  We will use the MNIST dataset which is the 'Hello world' problem of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfjjxqk-4-VY"
      },
      "source": [
        "I always like to start my jupyter notebooks with this code because it fits the display window to my screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq3zQaj94-Vf"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JTIiJaMH4-We"
      },
      "source": [
        "### This tutorial was adapted from Deep Learning with Python Chollet, F. (2021). Deep Learning with Python (2nd ed.). Greenwich, CT, USA: Manning Publications Co."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7J8caRE4-Wv"
      },
      "source": [
        "Start with some definitions.\n",
        "Numerical data in an array are called [tensors](https://en.wikipedia.org/wiki/Tensor)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYhqLSfB4-W5"
      },
      "source": [
        "Scalars are 0-dimensional tensors (a single digit). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sq1dfmTjXx1r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 0 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd6j127g4-Xg"
      },
      "source": [
        "A 1-dimensional tensor is also called a vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iWxjAcgYF2H"
      },
      "outputs": [],
      "source": [
        "x = np.array([12, 1, 2, 3]) #create a vector\n",
        "print('The value of x is', x)\n",
        "print('The dimention of this tensor is', x.ndim) # 1 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZnkKqX74-YS"
      },
      "source": [
        "A 2-dimensional tensor is also called a matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw6vcniRYMga"
      },
      "outputs": [],
      "source": [
        "x = np.array([[12, 1, 2, 3],\n",
        "              [5, 6, 7, 8,],\n",
        "              [10, 11, 12, 12]])\n",
        "print('The value of x is', x) # Print the 3 x 4 matrix\n",
        "print('The dimension of this tensor is', x.ndim) # 2 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDXBkNgF4-ZH"
      },
      "source": [
        "We can create n-dimensional tensors easily, although they become difficult to visualize.\n",
        "This 3D tensor is like a cube of data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7unoEvdhYbYR"
      },
      "outputs": [],
      "source": [
        "x = np.array([[[12, 1, 2, 3],\n",
        "               [5, 6, 7, 8,],\n",
        "               [10, 11, 12, 12]],\n",
        "              [[2, 2, 2, 2,],\n",
        "               [3,3,3,3],\n",
        "               [4,4,4,4]],\n",
        "              [[5,5,5,5],\n",
        "               [6,6,6,6],\n",
        "               [7,7,7,7]]])\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 3 dimensional array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QrNkyOM4-Z0"
      },
      "source": [
        "#### Reshaping tensors is an important concept to understand.  We can reshape a tensor as long as it has the same number of elements as the initial tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5jul5ly4-Z6"
      },
      "outputs": [],
      "source": [
        "x = x.reshape(3*3*4,1)\n",
        "print(x)\n",
        "x = x.reshape(4, 3*3)\n",
        "print(x)\n",
        "x = x.reshape(2, 18)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihVQabEo4-aS"
      },
      "source": [
        "##### Tensors have three attributes:\n",
        "- Number of axes (dimensions)\n",
        "- Shape (length of each axis)\n",
        "- Data type (typically we will use `float32`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2vP9ckYvLuh"
      },
      "source": [
        "We can also manipulate tensors with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XE9M6y1vULu"
      },
      "outputs": [],
      "source": [
        "# Import Tensorflow as tf\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diW1WriOvbms"
      },
      "outputs": [],
      "source": [
        "x = tf.ones(shape=(2,1))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMv_KG8pv6iq"
      },
      "outputs": [],
      "source": [
        "# Create a Tensorflow variable\n",
        "v = tf.Variable(initial_value=tf.random.normal(shape=(3,1)))\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iljsFGcewSIE"
      },
      "outputs": [],
      "source": [
        "# Once the variable is created it can be modified using assign\n",
        "v2 = v.assign(tf.random.normal(shape=(3,1)))\n",
        "print(v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGkCIydvw2Ks"
      },
      "outputs": [],
      "source": [
        "# Now we can perform some math operations on the tensors\n",
        "np.dot(v, v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdzH71UFxQ2Q"
      },
      "outputs": [],
      "source": [
        "# We get the above error because the shapes of v and v2 do not align properly for a dot product.\n",
        "print(v.shape)\n",
        "print(v2.shape)\n",
        "\n",
        "# For a dot product to alight the column rows of X must match the rows of Y. (See Figure 2.5 in book)\n",
        "# Therefore, we must transpose v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSctb3a0x8l-"
      },
      "outputs": [],
      "source": [
        "v3 = np.transpose(v2)\n",
        "print(v.shape)\n",
        "print(v3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l560ng4tyOdG"
      },
      "outputs": [],
      "source": [
        "# Now the rows of v match the columns of v3 we can take the dot product\n",
        "np.dot(v, v3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUA1N4pS4-aY"
      },
      "source": [
        "# Let's build our first neural net\n",
        "\n",
        "Load the MNIST library which is part of [Keras](https://keras.io/datasets/).  MNIST stands for [Modified National Institute of Standards and Technology](https://en.wikipedia.org/wiki/MNIST_database). It is a collection of 60,000 training and 10,000 test images of the digits 0-9. We will build a deep learning nerual net model to classify the 10 digits. This is the 'Hello World' problem of deep learning. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AG-iMB8P3DZ"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Efu6_zaQKtQ"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYu3aOo4Qn9R"
      },
      "outputs": [],
      "source": [
        "train_images.shape #60,000 images that are 28 pixles by 28 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73Jt87YRZBXe"
      },
      "outputs": [],
      "source": [
        "train_images.ndim #3D tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_fgMe2h4-bm"
      },
      "outputs": [],
      "source": [
        "print('The maximum value in the array is', train_images.max()) # The maximum value in the array is 255\n",
        "print('The minimum value in the array is', train_images.min()) # The minimum value in the array is 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvcS2anBQ8cd"
      },
      "outputs": [],
      "source": [
        "# Get the shape, dimensions, max and min value of the test images\n",
        "print('test image shape:', test_images.shape)\n",
        "print('number of dimensions:', test_images.ndim)\n",
        "print('maximum value', test_images.max())\n",
        "print('minimum value:', test_images.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAWThxtY4-co"
      },
      "source": [
        "In general, the first axis in a tensor is the samples, the second axis is height, the third axis is the width, and the fourth is color channels (3 for RGB data, and 1 for black and white). So image data will typically be a 4D tensor -- `[samples, height, width, channels]`, while the MNIST data is 3D because the color channel is black and white and can thus be ignored.\n",
        "Video data will be a 5D tensor -- `[samples, frames, height, width, channels]`. By convention, time series data will be placed on the secod axis when present"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kavsqyWG4-cZ"
      },
      "source": [
        "Let's view one of the images.  We need to import matplotlib to view the digits "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwEiakpiZXnf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvYknn0hZf51"
      },
      "outputs": [],
      "source": [
        "digit = train_images[4] # Select the fourth sample.\n",
        "plt.imshow(digit, cmap=plt.cm.binary) # Show the sample.  cmap is the color map.  We will keep it black and white (binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_eEPRIC9bb1"
      },
      "source": [
        "The 4th train image looks like the number 9.  Lets make sure the label matches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srjlYOAavZUW"
      },
      "outputs": [],
      "source": [
        "train_labels[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSBcnrgsRPJ3"
      },
      "outputs": [],
      "source": [
        "# Import models and layers from the keras library\n",
        "from keras import models\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWKxgF2L9_xG"
      },
      "source": [
        "We will be working with sequential models and *dense layers*. More on what those mean later.  Another name for a dense layer is a *fully connected layer*.  The dense layer must be one-dimensional. Therefore, the input image matrix must be reshaped into a vector. There are 60,000 test images with a shape of 28 x 28. We will reshape each image into a vector of length 28 * 28 == 784.\n",
        "\n",
        "We pick the `relu` activation function for our first layer and our output layer activation function is `softmax` because we have a multiclass classification problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8lxhcrHRV0x"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkdeEsM8FztX"
      },
      "source": [
        "Now we compile the model.  We use the `adam` optimizer and choose `categorical_crossentropy` for the loss function because it is a multiclass classification problem. We will evaluate our model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcixP8_xR5j7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERD4fJuF_n2l"
      },
      "source": [
        "Now the model is built and compiled we need to process the images for the model.  The images need to be reshaped into a vector of the same dimentions as the input shape above.  We also normalize the values of the images to be between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEeckA5ESIMB"
      },
      "outputs": [],
      "source": [
        "scale_factor = train_images.max()\n",
        "train_images =  train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32')/scale_factor\n",
        "\n",
        "test_images =  test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32')/scale_factor\n",
        "\n",
        "print(train_images.ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw_1wSzI4-ex"
      },
      "outputs": [],
      "source": [
        "print('train image shape:', train_images.shape)\n",
        "print('number of dimensions:', train_images.ndim)\n",
        "print('maximum value', train_images.max())\n",
        "print('minimum value:', train_images.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8QVj91nADix"
      },
      "outputs": [],
      "source": [
        "# We can always get our images back by reshaping to a matrix.\n",
        "plt.imshow(train_images.reshape((60000,28,28))[4], cmap=plt.cm.binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeczsZHUVDQx"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9u7dxrQGsi8"
      },
      "outputs": [],
      "source": [
        "# We need to convert the labels into catergorical values.\n",
        "# We can check the train lables for the 4th value to ensure\n",
        "# it is labeled as 9\n",
        "print(train_labels[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w90ZrgWhVPC1"
      },
      "outputs": [],
      "source": [
        "# Batch size is how many images to process at once. \n",
        "# Epoch is how many times to repeat the analysis.  \n",
        "# Each epoch performs 500 gradient updates (60,000/120 = 500)\n",
        "model.fit(train_images, train_labels, epochs = 5, batch_size = 120) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHqqd_YYVdz3"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIRCQyZ2F24o"
      },
      "source": [
        "# Your Turn.\n",
        "# Below is your assignment\n",
        "####  Build 3 different models with a dense layer with `relu` activation.  The output layer activation must be `softmax` since we have a multiclass problem.  You will compile the three different models with different optimizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgHnMI6T4-f6"
      },
      "outputs": [],
      "source": [
        "model1 = models.Sequential()\n",
        "model1.add(layers.Dense(512, activation='', input_shape=(28 * 28,)))\n",
        "model1.add(layers.Dense(10, activation=''))\n",
        "\n",
        "model2 = models.Sequential()\n",
        "model2.add(layers.Dense(512, activation='', input_shape=(28 * 28,)))\n",
        "model2.add(layers.Dense(10, activation=''))\n",
        "\n",
        "\n",
        "model3 = models.Sequential()\n",
        "model3.add(layers.Dense(512, activation='', input_shape=(28 * 28,)))\n",
        "model3.add(layers.Dense(10, activation=''))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnUDSgXk4-gE"
      },
      "source": [
        "#### Compile your three models with three different optimizers. Page 89 - 90 of the tetbook list some different optimizers.  You can also find more optimizers and documentation here: https://keras.io/api/optimizers/\n",
        "#### Use `categorical_crossentropy` for loss since this problem is a multiclass classification problem. The metric will be `accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhHGydeC4-gH"
      },
      "outputs": [],
      "source": [
        "model1.compile(optimizer='',\n",
        "               loss='',\n",
        "               metrics=[''])\n",
        "\n",
        "model2.compile(optimizer = '',\n",
        "               loss='',\n",
        "               metrics=[''])\n",
        "\n",
        "model3.compile(optimizer='',\n",
        "               loss='',\n",
        "               metrics=[''])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7uSP2vm4-gR"
      },
      "source": [
        "#### Fit the models with epochs = 5 and  batch_size = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9qFLRMA4-gT"
      },
      "outputs": [],
      "source": [
        "print('Fitting model 1...')\n",
        "model1.fit(train_images, train_labels, epochs=5, batch_size=120)\n",
        "print('Fitting model 2...')\n",
        "model2.fit(train_images, train_labels, epochs=5, batch_size=120)\n",
        "print('Fitting model 3...')\n",
        "model3.fit(train_images, train_labels, epochs=5, batch_size=120)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB4RPCz54-gb"
      },
      "source": [
        "#### Test the accuracy of the model on the test images and test labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7V6DjwV4-gc"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model1.evaluate(test_images, test_labels)\n",
        "print('model1_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = model2.evaluate(test_images, test_labels)\n",
        "print('model2_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = model3.evaluate(test_images, test_labels)\n",
        "print('model3_test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbR0ds5G4-gm"
      },
      "source": [
        "# Which optimizer gave the highest accuracy? Write you answer below\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqn4SN0ka7bt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD5Pjrqpa36e"
      },
      "source": [
        "### Using the optimizer that gave the highest accuracy compile 3 different models with 3 hidden layers and varying units in each hidden layer.  The first  layer is given to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTh369rD4-gr"
      },
      "outputs": [],
      "source": [
        "h1_model = models.Sequential()\n",
        "h1_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "h1_model.add(layers.Dense(, activation=''))\n",
        "h1_model.add(layers.Dense(, activation=''))\n",
        "h1_model.add(layers.Dense(, activation=''))\n",
        "h1_model.add(layers.Dense(, activation=''))\n",
        "\n",
        "h2_model = models.Sequential()\n",
        "h2_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "h2_model.add(layers.Dense(, activation=''))\n",
        "h2_model.add(layers.Dense(, activation=''))\n",
        "h2_model.add(layers.Dense(, activation=''))\n",
        "h2_model.add(layers.Dense(, activation=''))\n",
        "\n",
        "h3_model = models.Sequential()\n",
        "h3_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "h3_model.add(layers.Dense(, activation=''))\n",
        "h3_model.add(layers.Dense(, activation=''))\n",
        "h3_model.add(layers.Dense(, activation=''))\n",
        "h3_model.add(layers.Dense(, activation=''))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY-vLrzS4-g1"
      },
      "source": [
        "#### Complie the three models with the best optimizer from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvYLN-Ld4-g3"
      },
      "outputs": [],
      "source": [
        "h1_model.compile(optimizer='',\n",
        "               loss='',\n",
        "               metrics=[''])\n",
        "\n",
        "h2_model.compile(optimizer='',\n",
        "               loss='',\n",
        "               metrics=[''])\n",
        "\n",
        "h3_model.compile(optimizer='',\n",
        "               loss='',\n",
        "               metrics=[''])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRMZ56yI4-hF"
      },
      "source": [
        "#### Fit the models with epochs = 5 and  batch_size = 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO_mcJ9x4-hI"
      },
      "outputs": [],
      "source": [
        "print('Fitting model h1...')\n",
        "h1_model.fit()\n",
        "print('Fitting model h2...')\n",
        "h2_model.fit()\n",
        "print('Fitting model h3...')\n",
        "h3_model.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Kcmj6x4-hU"
      },
      "source": [
        "#### Test the accuracy of the 3 models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRUw9R5F4-ha"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = h1_model.evaluate(test_images, test_labels)\n",
        "print('h1_model_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = h2_model.evaluate(test_images, test_labels)\n",
        "print('h2_model_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = h3_model.evaluate(test_images, test_labels)\n",
        "print('h3_model_model_model_test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-fHqdpQ4-hm"
      },
      "source": [
        "#### Which model gave the highest accuracy? Write you answer below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY-GKvZYVgw9"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2-fHqdpQ4-hm"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
