{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Reuters_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FejM0cEQXUP"
      },
      "source": [
        "# Reuters Assingment\n",
        "## Adapted from Deep Learning with Python by Francois Chollet\n",
        "#### Using the IMDB jupyter notebook as an example follow the prompts below to build a neural network to classify Reuters news wires into 46 different categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLYzbicKQXUX"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFH2CgDRQXVZ"
      },
      "source": [
        "# Add the necessary libraries and load the data.\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kckdgba5QXV2"
      },
      "source": [
        "import operator\n",
        "# Print the word index\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35rwRsIeQXWZ"
      },
      "source": [
        "# Here is the same function we created for vectorizing the IMDB data.\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez2s5K3ZQXW2"
      },
      "source": [
        "# Vectorize the train_data and test_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN3CPRWGQXXG"
      },
      "source": [
        "# Print the unique train labels (there should be 46)\n",
        "# Print the shape of x_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQdFycDNQXXP"
      },
      "source": [
        "# Keras has a built in function for catergoial encoding which we saw in the MNIST workbook\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB6Irop5QXXY"
      },
      "source": [
        "# Convert the labels to cateforical\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP9I_bOUQXXk"
      },
      "source": [
        "# Import models and layers from Keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIXltq67QXXw"
      },
      "source": [
        "# Build a sequential model network with 1 hidden layer. The input and hidden layer must have more hidden units than the number of classification categories.\n",
        "# Things to think about, input and hidden layer activation, output activation for a multiclass problem, input shape, output units\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKDPXa4VQXX9"
      },
      "source": [
        "# Compile the model. Think about what optimizer, loss function, and metrics will you use.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bogp4BrGQXYJ"
      },
      "source": [
        "# Train your model on the training data for 20 epochs and 500 batch size and a validation split = 20%.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFMw_I8FQXYU"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a93HH_RGTlw5"
      },
      "source": [
        "# Use this bit of code to view the History output.\n",
        "hist = pd.DataFrame(history.history)\n",
        "print(hist.tail())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UC1Wq-0QXYd"
      },
      "source": [
        "# Let's plot the loss and accuracy vs epochs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtdrPkJBQXYk"
      },
      "source": [
        "# Use the IMDB example to plot the validataion and training loss vs epocs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBDWbbJUQXYt"
      },
      "source": [
        "# Use the IMDB example to plot the validataion and training accuracy vs epocs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR-uHo3lQXYy"
      },
      "source": [
        "# Evaluate the model on the test data and print the results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear your session using this command: backend.clear_session() \n",
        "Build a new model and try to get the  accuracy as high as you can. Copy your best model the end of the notebook.\n",
        "Things to try: more hidden layers and hiddent units, activation types, epochs, batch size, and validation_split.\n",
        "Try as many models as you like.  \n",
        "\n",
        "Be sure to clear the session each time.  backend.clear_session() Copy your best model the end of the notebook.\n"
      ],
      "metadata": {
        "id": "JPH31AvJtx35"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xy1Q-QwQXZB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}