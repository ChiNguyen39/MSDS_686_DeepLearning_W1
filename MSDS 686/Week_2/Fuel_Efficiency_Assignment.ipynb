{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KVqVcVDo9aUi"
      },
      "source": [
        "# Fuel Efficiency Assignment\n",
        "## Adapted from TensorFlow Tutorials\n",
        "Using the [Boston Housing jupyter notebook](Boston_Housing_Example.ipynb) as an example follow the prompts below to build a neural network to predict vehicle fuel efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuLZ2hhn9aUs"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB-uz88U9aVH"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import backend\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHSh7Wz79iiN"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joNdceRk9aVX"
      },
      "outputs": [],
      "source": [
        "# Add labels to columns and view dataset\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_McGq3q_MPS"
      },
      "outputs": [],
      "source": [
        "# Vehicle origin needs to be encoded to factors.  \n",
        "origin = dataset.pop('Origin')\n",
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQWXC9pi_DHE"
      },
      "outputs": [],
      "source": [
        "# Remove missing data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKLtoKX2OTvJ"
      },
      "outputs": [],
      "source": [
        "# Split dataset into targets, y, and remove from the dataset.  We are predicting MPG (fuel efficiency)\n",
        "# so the targets are MPG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EADoX6GgN22P"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into X_train, X_test, y_train, y_test.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwsKJwj_PNZa"
      },
      "outputs": [],
      "source": [
        "# Normalize the data by subtracting the mean from each feature and divide by one standard deviation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX2i2EUn_BHT"
      },
      "outputs": [],
      "source": [
        "# Built a sequential neural network model.  Start with backend.clear_session()\n",
        "# Think about what activation function you will use, the input shape, number of nodes, and output shape and activation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3mv0oLBR3XW"
      },
      "outputs": [],
      "source": [
        "# Compile the model.  Use 'rmsprop' optimizer.  Think about what loss function and metrics you need to use for a\n",
        "# regression problem and add it below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ8KVfLF_Hv1"
      },
      "outputs": [],
      "source": [
        "# Fit the model.  Use 1000 epochs.  Add a validation split to your model.  Set verbose = 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRfKjuM8UB5T"
      },
      "outputs": [],
      "source": [
        "# Use this bit of code to view the History output.\n",
        "hist = pd.DataFrame(history.history)\n",
        "display(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr819dPc9aXk"
      },
      "outputs": [],
      "source": [
        "#Get the loss and MAE vs epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXiqSkQo9aXs"
      },
      "outputs": [],
      "source": [
        "# Use the Boston Housing example to plot the validation and training loss vs epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04CcZh8x9aYH"
      },
      "outputs": [],
      "source": [
        "# Use the Boston Housing example to plot the validation and training mean absolute error vs epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RRZWTz_9aYR"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test data and print the results\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3hDjoWArs6r-"
      },
      "source": [
        "Build a new model and try to get the  accuracy as high as you can. Things to try: more hidden layers and hidden units, activation types, epochs, batch size, and validation_split. Try as many models as you like.  \n",
        "\n",
        "Be sure to clear the session each time: `backend.clear_session()`. Copy your best model at the end of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oadmVPacs6HD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Fuel_Efficiency_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
